THOSE who’ve been raising alarms about Facebook are right: Almost every minute that we spend on our smartphones and tablets and laptops, thumbing through favorite websites and scrolling through personalized feeds, we’re pointed toward foregone conclusions. We’re pressured to conform.
提醒大家要警惕Facebook的人并没有说错：我们在智能手机、平板和笔记本电脑上花费的每一分钟，浏览喜欢的网页、阅读个性化的消息，都被导向了预设的结论。我们遭受了保持一致的压力。
But unseen puppet masters on Mark Zuckerberg’s payroll aren’t to blame. We’re the real culprits. When it comes to elevating one perspective above all others and herding people into culturally and ideologically inflexible tribes, nothing that Facebook does to us comes close to what we do to ourselves.
不过，罪魁祸首并非马克·扎克伯格(Mark Zuckerberg)手下的那些看不见的操纵大师，我们自己才是。说起来，我们自己远比Facebook更擅长于将一种观点凌驾于其他观点之上，并把人禁锢到文化与意识形态的僵化牢笼里。
I’m talking about how we use social media in particular and the Internet in general — and how we let them use us. They’re not so much agents as accomplices, new tools for ancient impulses, part of “a long sequence of technological innovations that enable us to do what we want,” noted the social psychologist Jonathan Haidt, who wrote the 2012 best seller “The Righteous Mind,” when we spoke last week.
我想说的是我们的行为方式，尤其是如何使用社交媒体，以及整个互联网——我们又如何任由它们驾驭自己。上周与我进行探讨时，著有2012年畅销书《正义之心》(The Righteous Mind)的社会心理学者乔纳森·海特(Jonathan Haidt)表示，与其说它们是动因，还不如说是同谋，一种古老冲动的新工具，属于“让我们得以随心所欲的一长串技术革新”的一部分。
“And one of the things we want is to spend more time with people who think like us and less with people who are different,” Haidt added. “The Facebook effect isn’t trivial. But it’s catalyzing or amplifying a tendency that was already there.”
“我们的一个欲望就是，多跟想法类似的人在一起，避开意见相左的人，”海特还说。“Facebook效应并非微不足道，而是在催化或放大本已存在的倾向。”
By “the Facebook effect” he didn’t mean the possibility, discussed extensively over recent weeks, that Facebook manipulates its menu of “trending” news to emphasize liberal views and sources. That menu is just one facet of Facebook.
谈到“Facebook效应”的时候，他指的并不是过去几周里被广泛讨论的一种可能性——Facebook有意操控其“热门”新闻菜单，从而强调自由派的观点和信源。菜单不过是Facebook的一个方面。
More prevalent for many users are the posts we see from friends and from other people and groups we follow on the network, and this information is utterly contingent on choices we ourselves make. If we seek out, “like” and comment on angry missives from Bernie Sanders supporters, we’ll be confronted with more angry missives from more Sanders supporters. If we banish such outbursts, those dispatches disappear.
对许多用户而言，更常见的是我们看到的好友及在网上关注的个人和团体的发帖，而这些信息完全取决于我们自己做的选择。倘若我们寻找、“点赞”或评论伯尼·桑德斯(Bernie Sanders)支持者的愤怒言论，就会遇到更多桑德斯支持者的更多愤怒言论。假如我们唾弃此类情绪冲动，这类帖子就会消失。
That’s the crucial dynamic, algorithm or whatever you want to call it. That’s the trap and curse of our lives online.
这就是其中关键的“影响力量”、“算法”，或者爱叫什么名字都可以。这就是我们网络生活的陷阱与诅咒。
The Internet isn’t rigged to give us right or left, conservative or liberal — at least not until we rig it that way. It’s designed to give us more of the same, whatever that same is: one sustained note from the vast and varied music that it holds, one redundant fragrance from a garden of infinite possibility.
互联网本身并未受到操纵来向我们投喂右翼或左翼观念、保守派或自由派思想，或者起码要等到我们自己操纵它这样做之后。它的设计目标就是给我们送来更多类似的东西，不管这东西究竟是什么：浩如烟海的乐章中的一个持续音，百花齐放的花园里的一种单调香味。
A few years back I bought some scented shower gel from Jo Malone. I made the purchase through the company’s website. For months afterward, as I toggled through cyberspace, Jo Malone stalked me, always on my digital heels, forever in a corner of my screen, a Jo Malone candle here, a Jo Malone cologne over there. I’d been profiled and pigeonholed: fan of Jo Malone. Sure, I could choose from woody, citrus, floral and even fruity, but there was no Aramis in my aromatic ecosphere, and I was steered clear of Old Spice.
几年前，我买了祖·玛珑(Jo Malone)品牌的某种芳香沐浴啫喱。我是从这家公司的网站上购买的。接下来的好几个月里，只要我在网络世界里游荡，祖·玛珑就会追踪，总是跟在我的数字身影后面，永远占据了屏幕的一角，这里冒出个祖·玛珑蜡烛，那里蹦出个祖·玛珑古龙水。我被定了性、圈进了一个小门类：祖·玛珑粉丝。当然了，我可以从祖·玛珑的本木香、柑橘香、花香乃至果香中进行选择，但我的香味生态圈里没有了雅男士(Aramis)品牌，Old Spice的产品也统统离我远去了。
So it goes with the fiction we read, the movies we watch, the music we listen to and, scarily, the ideas we subscribe to. They’re not challenged. They’re validated and reinforced. By bookmarking given blogs and personalizing social-media feeds, we customize the news we consume and the political beliefs we’re exposed to as never before. And this colors our days, or rather bleeds them of color, reducing them to a single hue.
我们读的小说、看的电影、听的音乐也不例外，可怕的是，接触的思想亦如此。它们不会受到挑战，而是会不断自我证实和加强。通过给特定的博客加书签、将社交媒体讯息个性化，我们订制了自身消费的新闻和能够接触到的政治信仰，程度之深超过以前任何时候。这种行为决定了我们生活的色彩，或者更确切地说，是将生活中的色彩抽去，让它变得单调。
We construct precisely contoured echo chambers of affirmation that turn conviction into zeal, passion into fury, disagreements with the other side into the demonization of it. Then we marvel at the Twitter mobs that swarm in defense of Sanders or the surreal success of Donald Trump’s candidacy, whose historical tagline may well be “All I know is what’s on the Internet.”
我们构建了一道精心打造的正反馈回音壁，将确信变为狂热，将热情变为狂躁，将与他人的分歧变为妖魔化对方。于是我们惊讶地看到，有一群Twitter暴徒一窝蜂地为桑德斯辩护，或是唐纳德·特朗普(Donald Trump)竞选的超现实成功，而其一直以来的口号完全可以总结为，“我所知道的都来自互联网。”
Those were his exact words, a blithe excuse for his mistaken assertion that a protester at one of his rallies had ties to Islamic extremists. He’d seen a video somewhere. He’d chosen to take it at face value. His intelligence wasn’t and isn’t vetted but viral — and conveniently suited to his argument and needs. With a creative or credulous enough Google search, a self-serving “truth” can always be found, along with a passel of supposed experts to vouch for it and a clique of fellow disciples.
这其实就是他的原话，为错误地断言自己竞选集会中的一名抗议者与伊斯兰主义极端分子有关联而勉强找的借口。他在哪里看到过一段视频，他选择信以为真。他的情报过去和现在都没有进行过核实，却飞速流传开来——完美契合了他的观点和需求。用谷歌来一番足够有创意的搜索，或者有足够的意愿去相信搜索结果，总能找到符合自身要求的“真相”，外加一大批所谓的专家为其打包票，以及一群同样的追随者。
Carnival barkers, conspiracy theories, willful bias and nasty partisanship aren’t anything new, and they haven’t reached unprecedented heights today. But what’s remarkable and sort of heartbreaking is the way they’re fed by what should be strides in our ability to educate ourselves. The proliferation of cable television networks and growth of the Internet promised to expand our worlds, not shrink them. Instead they’ve enhanced the speed and thoroughness with which we retreat into enclaves of the like-minded.
疯狂的咆哮者、阴谋理论、有意的歧视和严重的党派偏见，这些都不是什么新鲜事物，它们也还没有达到前所未有的程度。但它们滋长的方式比较引人注目，也有些让人难以接受，是本该让我们在自我教育上获得巨大进步的东西助长了它们。有线电视台的激增和互联网的快速发展本该扩展，而非缩小我们的视野。但它们反倒让我们更快和更彻底地陷入党同伐异的小圈子。
Eli Pariser parsed all of this in his 2011 book “The Filter Bubble,” noting how every tap, swipe and keystroke warps what comes next, creating a tailored reality that’s closer to fiction. There was subsequent pushback to that analysis, including from scientists at Facebook, who published a peer-reviewed study in the journal Science last year that questioned just how homogeneous a given Facebook user’s news feed really was.
在2011年出版的《过滤泡沫》(The Filter Bubble)一书中，埃利·帕里泽(Eli Pariser)详细分析了所有这一切，他解释了每一次点击、刷新和敲击键盘如何让接下来出现的信息发生变形，由此创造出一种近乎于虚构的量身定制的现实。有人对这种分析进行了驳斥，其中包括来自Facebook的科学家。后者去年在《科学》杂志发表了一篇经过同行评议的论文，对某个特定的Facebook用户订阅的新闻信息非常同质化的观点予以质疑。
But there’s no argument that in an era that teems with choice, brims with niche marketing and exalts individualism to the extent that ours does, we’re sorting ourselves with a chillingly ruthless efficiency. We’ve surrendered universal points of reference. We’ve lost common ground.
但有一点毋庸置疑的，即在这样一个充满选择、包含无数小众市场和将个性化推崇到无以复加的时代，我们在用一种干脆利落到让人恐惧的效率进行自我分类。我们放弃了普遍适用的参照点。我们丧失了共同点。
“Technology makes it much easier for us to connect to people who share some single common interest,” said Marc Dunkelman, adding that it also makes it easier for us to avoid “face-to-face interactions with diverse ideas.” He touched on this in an incisive 2014 book, “The Vanishing Neighbor,” which belongs with Haidt’s work and with “Bowling Alone,” “Coming Apart” and “The Fractured Republic” in the literature of modern American fragmentation, a booming genre all its own.
“技术进步让我们更容易和那些与自己有单一共同兴趣点的人产生连接，”马克·邓克尔曼(Marc Dunkelman)说道。他还表示，技术也让我们更容易避开“不同的观念”，避免“直接与之相互影响”。他在自己2014年那本深刻透彻的著作《消失的邻居》(The Vanishing Neighbor)中谈到了这个问题。这本著作和海特的《正义之心》，以及《独自打保龄》(Bowling Alone)、《分离》(Coming Apart)和《分裂的共和国》(The Fractured Republic)等都属于描绘现代美国人分化状况的著作，而这也是一个正在蓬勃发展的作品类型。
We’re less committed to, and trustful of, large institutions than we were at times in the past. We question their wisdom and substitute it with the groupthink of micro-communities, many of which we’ve formed online, and their sensibilities can be more peculiar and unforgiving.
相比于过去有些时候，我们如今更加不信任和不愿把自己托付给大型机构。我们质疑这类机构的智识，以微社区的群体思考取而代之。这些微社区有很多是我们在网上组建，其情感可能更为独特，更不具包容性。
Facebook, along with other social media, definitely conspires in this. Haidt noted that it often discourages dissent within a cluster of friends by accelerating shaming. He pointed to the enforced political correctness among students at many colleges.
Facebook和其他社交媒体肯定在这个过程中起到了作用。海特提到，它往往不鼓励一群朋友中出现异见，因为更容易让持不同意见的人感觉没面子。他指出，不少学院里的学生中出现了有强制性的政治正确。
“Facebook allows people to react to each other so quickly that they are really afraid to step out of line,” he said.
“因为有了Facebook，人们的互动变得如此迅速，以致他们很害怕自己没与集体保持一致，”他说。
But that’s not about a lopsided news feed. It’s not about some sorcerer’s algorithm. It’s about a tribalism that has existed for as long as humankind has and is now rooted in the fertile soil of the Internet, which is coaxing it toward a full and insidious flower.
不过，这里不是特别针对某个一边倒的新闻订阅服务，也不关乎某种神奇的算法，而说的是一种部落意识。自人类出现，这种部落意识就已经存在，现在更是扎根于肥沃的互联网土壤之中。在其滋养下，这种意识即将进入盛放时期，开出危险的花朵。